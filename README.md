# Hyperparamters_Tuning(Gridsearch et HyperOpt) 
Pour augmenter la performance des algorithmes de machine learning, les data scientists ont recours aux techniques de tuning des hyperparametres.  

Pour identifier les paramètres essentiels des algorithmes et corriger le sur-apprentissage et le sous-apprentissage, le tuning des hyperparameters permet de pallier ces inperfections. 
L’hyperparameters tuning est une étape importante du machine learning. Il consiste à trouver la bonne combinaison d’hyperparamètres permettant de minimiser l’erreur d’estimation et aussi de parer d’éventuels problèmes d’overfitting(forte variabilité)  ou d’underfitting(problème de biais) . Les méthodes classiques d’hyperparameters tuning sont le grid search et  le random search  disponibles sur Sklearn. Il existe aussi d’autres alternatives telles HyperOpt et hpsklearn qui permettent à la fois le choix de modèle (autoML) et l’optimisation d’hyperparamètres.
